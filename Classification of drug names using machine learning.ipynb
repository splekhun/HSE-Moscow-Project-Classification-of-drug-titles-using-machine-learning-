{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa4e7bae",
   "metadata": {},
   "source": [
    "# Аттестационный проект на тему \"Классификация названий лекарственных средств\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c06bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stop_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2deccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import stop_words\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import re\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from sklearn.preprocessing import MultiLabelBinarizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e4c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407330ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"utitles_cats_short.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bec95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea022e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a59814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Категория'] = df['Категория'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e24e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Название'] = df['Название'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Категория.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a091b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = get_stop_words('ru')\n",
    "russian_stopwords.extend(['...', '«', '»', 'здравствуйте', 'здравствуй', 'до свидания', 'добрый день', 'добрый вечер', 'в', 'внимание', 'неопознанный', 'товар', 'яяя'])\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([ch if ch not in string.punctuation else ' ' for ch in text])\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return ''.join([i if not i.isdigit() else ' ' for i in text])\n",
    "\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "prep_text = [remove_multiple_spaces(remove_punctuation(text.lower())) for text in df['Категория'].astype('str')]\n",
    "df['Категория'] = prep_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dcf190",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_title = [remove_multiple_spaces(remove_punctuation(text.lower())) for text in df['Название'].astype('str')]\n",
    "df['Название'] = prep_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['Категория']\n",
    "\n",
    "def tokenize_drugs(data):\n",
    "    for drug in data:\n",
    "        tokens = word_tokenize(drug)\n",
    "        #print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a48d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_counts = df.groupby('Категория')['Категория'].agg('count').values\n",
    "balance_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897c889",
   "metadata": {},
   "source": [
    "Попробуем подобрать параметры с помощью GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['Название']\n",
    "categories = df['Категория']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(texts, categories, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d376e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение пайплайна\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение параметров для Grid Search\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # униграммы или биграммы\n",
    "    'clf__max_iter': (20,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa458a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск по сетке\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac74826",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лучшие параметры и оценка модели\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание на тестовой выборке\n",
    "y_pred1 = grid_search.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf8412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка качества модели\n",
    "accuracy = accuracy_score(y_test1, y_pred1)\n",
    "precision = precision_score(y_test1, y_pred1, average='weighted')\n",
    "recall = recall_score(y_test1, y_pred1, average='weighted')\n",
    "f1 = f1_score(y_test1, y_pred1, average='weighted')\n",
    "\n",
    "print(f\"Точность (accuracy): {accuracy}\")\n",
    "print(f\"Точность (precision): {precision}\")\n",
    "print(f\"Полнота (recall): {recall}\")\n",
    "print(f\"F-мера (f1 score): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5bc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1489a2e9",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b576e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание экземпляра CountVectorizer с использованием собственной функции предварительной обработки\n",
    "tfidf = TfidfVectorizer(norm=None, max_df=0.75, max_features=500, decode_error='replace') # 1) min_df=0.1 2)min_df=0.5\n",
    "\n",
    "# Преобразование всех данных\n",
    "X = tfidf.fit_transform(texts.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Категория'] if 'Категория' in df.columns else [0] * len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем данные на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc345d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4faa271",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_clf = LogisticRegression(random_state=64, solver='lbfgs', max_iter=20, n_jobs=-1) # Обучаем классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_train_pred = LR_clf.predict(X_train)\n",
    "LR_test_pred = LR_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86089fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30714beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод результатов\n",
    "\n",
    "accuracy_score(y_train, LR_train_pred), accuracy_score(y_test, LR_test_pred)\n",
    "     \n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, LR_train_pred), accuracy_score(y_test, LR_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tfidf = accuracy_score(y_test, y_pred)\n",
    "precision_tfidf = precision_score(y_test, y_pred, average='weighted')\n",
    "recall_tfidf = recall_score(y_test, y_pred, average='weighted')\n",
    "f1_tfidf = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_tfidf, precision_tfidf, \n",
    "                                                                       recall_tfidf, f1_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515c3d7",
   "metadata": {},
   "source": [
    "Наримуем схему пайплайна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2273db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта графа\n",
    "dot = Digraph(comment='Text Classification Pipeline')\n",
    "\n",
    "# Добавление узлов (элементов пайплайна)\n",
    "dot.node('A', 'Raw Text Data')\n",
    "dot.node('B', 'CountVectorizer')\n",
    "dot.node('C', 'TfidfTransformer')\n",
    "dot.node('D', 'SGDClassifier')\n",
    "\n",
    "# Добавление рёбер (соединений между элементами)\n",
    "dot.edge('A', 'B', label='vect__max_df: 1.0\\nvect__ngram_range: (1, 2)')\n",
    "dot.edge('B', 'C')\n",
    "dot.edge('C', 'D', label='clf__alpha: 1e-05\\nclf__max_iter: 20\\nclf__penalty: elasticnet')\n",
    "\n",
    "# Сохранение графа в файл\n",
    "dot.render('text_classification_pipeline', format='png')\n",
    "\n",
    "# Вывод графа\n",
    "dot.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация пайплайна\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b343c",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40acb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f209cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from huggingface_hub import hf_hub_download\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = KeyedVectors.load_word2vec_format(hf_hub_download(repo_id=\"Word2vec/wikipedia2vec_ruwiki_20180420_300d\", filename=\"ruwiki_20180420_300d.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словаря index_to_word\n",
    "index_to_word = {index: word for word, index in tfidf.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201def70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для преобразования разреженной матрицы обратно в текстовые данные\n",
    "def sparse_matrix_to_texts(matrix, index_to_word):\n",
    "    texts = []\n",
    "    for row in matrix:\n",
    "        words = [index_to_word[idx] for idx in row.indices for _ in range(int(row[0, idx]))]  # Учитываем частоты\n",
    "        texts.append(' '.join(words))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc756da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование разреженной матрицы X_train в текст\n",
    "texts_train = sparse_matrix_to_texts(X_train, index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение текстов на слова для Word2Vec\n",
    "sent = [text.split() for text in texts_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c29176",
   "metadata": {},
   "source": [
    "Сделаем первичную загрузку модели с huggingface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcca3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели Word2Vec на 300\n",
    "#model_path = hf_hub_download(repo_id=\"Word2vec/wikipedia2vec_ruwiki_20180420_300d\", filename=\"ruwiki_20180420_300d.txt\")\n",
    "#pretrained_model = KeyedVectors.load_word2vec_format(model_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7cb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=\"Word2vec/wikipedia2vec_ruwiki_20180420_100d\", filename=\"ruwiki_20180420_100d.txt\")\n",
    "pretrained_model = KeyedVectors.load_word2vec_format(model_path, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d296bb",
   "metadata": {},
   "source": [
    "Для повторной загрузки модели будем использовать следующую ячейку:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=\"Word2vec/wikipedia2vec_ruwiki_20180420_100d\", filename=\"ruwiki_20180420_100d.txt\")\n",
    "pretrained_model = KeyedVectors.load_word2vec_format(model_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация новой модели Word2Vec с использованием предобученных векторов, ДЕЛАЕМ ПЕРВЫЙ РАЗ\n",
    "model = Word2Vec(vector_size=pretrained_model.vector_size, window=2, min_count=1, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f70f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#уменьшим размер данный для тестирования\n",
    "small_sentences = sent[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ed0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение словаря из обучающих данных\n",
    "model.build_vocab(small_sentences) #sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительное обучение модели на ваших данных, уменьшим число эпох с 30 до 10\n",
    "model.train(small_sentences, total_examples=len(small_sentences), epochs=10, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученных векторов в модель\n",
    "model.wv.vectors = pretrained_model.vectors\n",
    "model.wv.index_to_key = pretrained_model.index_to_key\n",
    "model.wv.key_to_index = pretrained_model.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf80751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получение вектора слова:\n",
    "\n",
    "word_vector = model.wv['нурофен']  # Замените 'слово' на интересующее вас слово\n",
    "print(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ab961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Поиск похожих слов:\n",
    "\n",
    "similar_words = model.wv.most_similar('пенталгин', topn=10)  # Замените 'слово' на интересующее вас слово\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a143ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверка вектора:\n",
    "\n",
    "if 'аспирин' in model.wv:\n",
    "    print(f\"Вектор для 'аспирин': {model.wv['аспирин']}\")\n",
    "else:\n",
    "    print(\"Слово не найдено в модели.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec_model_100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1939fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пусть путь к вашей сохраненной модели будет таким\n",
    "model_path = \"word2vec_model_100.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KeyedVectors.load(\"word2vec_model_100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = df[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(texts, categories, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704894dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_words = 0\n",
    "total_words = 0\n",
    "\n",
    "for sent in X_train_w2v[0]:\n",
    "    for word in sent.split():\n",
    "        total_words += 1\n",
    "        if word not in model.wv:\n",
    "            unknown_words += 1\n",
    "\n",
    "print(f\"Unknown words: {unknown_words}\")\n",
    "print(f\"Total words: {total_words}\")\n",
    "print(f\"Percentage of unknown words: {unknown_words / total_words * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_w2v представляет собой список или другую структуру данных,создадим датафрэйм\n",
    "data = {'Название': X_train_w2v}  # Подставьте свои данные здесь\n",
    "\n",
    "# Создаем DataFrame из данных\n",
    "X_train_w2v_new = pd.DataFrame(data)\n",
    "\n",
    "# Выводим первые несколько строк для проверки\n",
    "print(X_train_w2v_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aff384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_w2v_vector(tokens, model, vector_size=100):  # Укажем размер вектора\n",
    "    word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "    mean_vector = np.mean(word_vectors, axis=0)\n",
    "    return mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение текста на токены\n",
    "X_train_w2v_new['tokens'] = X_train_w2v_new['Название'].apply(lambda x: x.split())\n",
    "\n",
    "# Применение функции для получения средних векторов\n",
    "X_train_w2v_new['vectors'] = X_train_w2v_new['tokens'].apply(lambda tokens: get_mean_w2v_vector(tokens, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c4099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X_train_w2v_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame для X_test_w2v\n",
    "data_test = {'Название': X_test_w2v}\n",
    "X_test_w2v_new = pd.DataFrame(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение текста на токены\n",
    "X_test_w2v_new['tokens'] = X_test_w2v_new['Название'].apply(lambda x: x.split())\n",
    "\n",
    "# Применение функции для получения средних векторов\n",
    "X_test_w2v_new['vectors'] = X_test_w2v_new['tokens'].apply(lambda tokens: get_mean_w2v_vector(tokens, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_w2v_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_new['tokens'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c98f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vocabulary size: {len(model.wv.index_to_key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d6263",
   "metadata": {},
   "outputs": [],
   "source": [
    "IdxTrain = [ix for ix, row in X_train_w2v_new.iterrows() if not isinstance(row['vectors'], np.ndarray) or np.all(row['vectors'] == 0)]\n",
    "IdxTest = [ix for ix, row in X_test_w2v_new.iterrows() if not isinstance(row['vectors'], np.ndarray) or np.all(row['vectors'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72edbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewCols = ['col'+str(i) for i in range(HIDDEN)]\n",
    "X_train_w2v_new[NewCols] = pd.DataFrame(X_train_w2v_new['vectors'].tolist(), index=X_train_w2v_new.index)\n",
    "X_test_w2v_new[NewCols] = pd.DataFrame(X_test_w2v_new['vectors'].tolist(), index=X_test_w2v_new.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bb3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка и сброс индексов в X_train_w2v_new\n",
    "X_train_w2v_new = X_train_w2v_new.reset_index(drop=True)\n",
    "\n",
    "# Проверка и сброс индексов в y_train_w2v\n",
    "y_train_w2v = y_train_w2v.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc40ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка и удаление несоответствующих строк\n",
    "to_drop = [idx for idx in X_train_w2v_new.index if idx >= len(y_train_w2v)]\n",
    "X_train_w2v_new = X_train_w2v_new.loc[~X_train_w2v_new.index.isin(to_drop)]\n",
    "y_train_w2v = y_train_w2v.loc[~y_train_w2v.index.isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# запуск модели Logistic Regression\n",
    "lr_clf_w2v = LogisticRegression(random_state=64, solver='lbfgs', max_iter=500, n_jobs=-1) # Увеличение max_iter, чтобы избежать предупреждений о сходимости\n",
    "lr_clf_w2v.fit(X_train_w2v_new[NewCols], y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания на обучающем и тестовом наборах данных\n",
    "lr_train_pred_w2v = lr_clf_w2v.predict(X_train_w2v_new[NewCols])\n",
    "lr_test_pred_w2v = lr_clf_w2v.predict(X_test_w2v_new[NewCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ff84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка точности на обучающем наборе данных\n",
    "train_accuracy_w2v = accuracy_score(y_train_w2v, lr_train_pred_w2v)\n",
    "print(f\"Training Accuracy: {train_accuracy_w2v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69218a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_w2v = accuracy_score(y_train_w2v, lr_train_pred_w2v)\n",
    "test_accuracy_w2v = accuracy_score(y_test_w2v, lr_test_pred_w2v)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy_w2v}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_w2v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f281b",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fabb4c",
   "metadata": {},
   "source": [
    "Чтобы установить glove на Python необходмо:\n",
    "Загрузить файл glove.6B.100d.txt с сайта GloVe или из другого репозитория.\n",
    "Установить библиотеку gensim, используя команду pip install gensim.\n",
    "Загрузить файл glove.6B.100d.txt в Python с помощью функции load_embeddings():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcac0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dea07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = 'C:/Users/shevr/Documents/Project HSE/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертируем файл формата GloVe в формат Word2Vec\n",
    "glove2word2vec(glove_file, 'glove_word2vec.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем модель GloVe с помощью библиотеки gensim\n",
    "glove_model = KeyedVectors.load_word2vec_format('glove_word2vec.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14667b99",
   "metadata": {},
   "source": [
    "Создадим словарь уникальных слов в нашем датасете.\n",
    "Разделим текст на токены и преобразуем их в список индексов словаря.\n",
    "Используем метод similarity() класса KeyedVectors для вычисления сходства между текстом и каждым классом в вашей задаче классификации.\n",
    "Выбераем класс с наибольшим значением сходства как предсказанный класс для данного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78379d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_glove_vector(tokens, glove_model, vector_size=100):\n",
    "    vectors = [glove_model[word] for word in tokens if word in glove_model]\n",
    "    if vectors:\n",
    "        mean_vector = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        mean_vector = np.zeros(vector_size)\n",
    "    return mean_vector\n",
    "\n",
    "# Пример использования\n",
    "X_train_w2v_new['glove_vectors'] = X_train_w2v_new['tokens'].apply(lambda tokens: get_mean_glove_vector(tokens, glove_model))\n",
    "\n",
    "print(X_train_w2v_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe088c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Список уникальных категорий\n",
    "unique_classes = df['Категория'].unique()\n",
    "\n",
    "# Разделим категории на отдельные слова\n",
    "class_words = [cls.split() for cls in unique_classes]\n",
    "\n",
    "# Проверим, какие слова есть в модели GloVe\n",
    "present_words = [word for sublist in class_words for word in sublist if word in glove_model]\n",
    "missing_words = [word for sublist in class_words for word in sublist if word not in glove_model]\n",
    "\n",
    "print(f\"Present words in GloVe: {present_words}\")\n",
    "print(f\"Missing words in GloVe: {missing_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24141076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание векторного представления для категорий\n",
    "class_vectors = {}\n",
    "for cls in unique_classes:\n",
    "    words = cls.split()\n",
    "    class_vectors[cls] = get_mean_glove_vector(words, glove_model)\n",
    "\n",
    "print(f\"Class vectors: {class_vectors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678827ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ff242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_classification(text_title, glove_model, class_vectors):\n",
    "    tokens = word_tokenize(text_title)  # Преобразование названия в токены\n",
    "    mean_vector = get_mean_glove_vector(tokens, glove_model)\n",
    "    \n",
    "    similarities = {}\n",
    "    for cls, vec in class_vectors.items():\n",
    "        similarities[cls] = 1 - cosine(mean_vector, vec)  # 1 - косинусное расстояние для сходства\n",
    "    \n",
    "    predicted_class = max(similarities, key=similarities.get)\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c20db41",
   "metadata": {},
   "source": [
    "Этот код принимает на вход текст и список классов, а возвращает предсказанный класс для данного текста с использованием модели GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18443d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример использования\n",
    "text_title = 'алмагель'\n",
    "predicted_class = glove_classification(text_title, glove_model, class_vectors)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4fc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eaa9d06",
   "metadata": {},
   "source": [
    "На основе моих данных нарисую пошаговую схему проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988777c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# Создание объекта графа\n",
    "dot = Digraph(comment='Классификация названий лекарственных средств')\n",
    "\n",
    "# Добавление узлов (элементов пайплайна)\n",
    "dot.node('A', 'Сбор данных')\n",
    "dot.node('B', 'Предобработка текста')\n",
    "dot.node('C', 'Векторизация')\n",
    "dot.node('D', 'Разделение данных')\n",
    "dot.node('E', 'Обучение модели')\n",
    "dot.node('F', 'Оценка модели')\n",
    "dot.node('G', 'Применение модели')\n",
    "\n",
    "# Добавление рёбер (соединений между элементами)\n",
    "dot.edge('A', 'B', label='Очистка данных')\n",
    "dot.edge('B', 'C', label='TF-IDF, Word2Vec, GloVe')\n",
    "dot.edge('C', 'D', label='Обучающая и тестовая выборки')\n",
    "dot.edge('D', 'E', label='Логистическая регрессия, SGDClassifier')\n",
    "dot.edge('E', 'F', label='Точность, полнота, F-мера')\n",
    "dot.edge('F', 'G', label='Классификация новых данных')\n",
    "\n",
    "# Сохранение графа в файл\n",
    "dot.render('drug_classification_pipeline', format='png')\n",
    "\n",
    "# Отображение графа\n",
    "dot.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
